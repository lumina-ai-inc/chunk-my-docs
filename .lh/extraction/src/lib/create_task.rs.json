{
    "sourceFile": "extraction/src/lib/create_task.rs",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 0,
            "patches": [
                {
                    "date": 1724532666296,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                }
            ],
            "date": 1724532666296,
            "name": "Commit-0",
            "content": "use actix_multipart::form::tempfile::TempFile;\nuse chrono::{ DateTime, Utc };\nuse dotenvy::dotenv;\nuse humantime;\nuse lopdf::Document;\nuse models::api::{\n    extraction::{ ExtractionPayload, ModelInternal },\n    task::{ Status, TaskResponse },\n};\nuse crate::models::rrq::produce::ProducePayload;\nuse crate::utils::deadpool_postgres::{ Client, Pool };\nuse crate::utils::rrq::service::produce;\nuse crate::utils::storage_service::services::upload_to_s3;\nuse std::env;\nuse std::error::Error;\nuse std::time::Duration;\nuse uuid::Uuid;\n\nfn is_valid_pdf(buffer: &[u8]) -> Result<bool, lopdf::Error> {\n    match Document::load_mem(buffer) {\n        Ok(_) => Ok(true),\n        Err(_) => Ok(false),\n    }\n}\n\nasync fn produce_extraction_payloads(\n    extraction_payload: ExtractionPayload\n) -> Result<(), Box<dyn Error>> {\n    let document_extraction_queue = env\n        ::var(\"EXTRACTION__QUEUE\")\n        .expect(\"EXTRACTION__QUEUE must be set\");\n\n    let produce_payload = ProducePayload {\n        queue_name: document_extraction_queue.clone(),\n        publish_channel: None,\n        payload: serde_json::to_value(extraction_payload).unwrap(),\n        max_attempts: None,\n        item_id: Uuid::new_v4().to_string(),\n    };\n\n    produce(vec![produce_payload]).await?;\n\n    Ok(())\n}\n\npub async fn create_task(\n    pool: &Pool,\n    file: &TempFile,\n    task_id: String,\n    user_id: String,\n    api_key: &String,\n    model: ModelInternal\n) -> Result<TaskResponse, Box<dyn Error>> {\n    dotenv().ok();\n    let mut client: Client = pool.get().await?;\n    let expiration = env\n        ::var(\"INGEST_SERVER__EXPIRATION\")\n        .ok()\n        .map(|val| val)\n        .or(None);\n    let created_at: DateTime<Utc> = Utc::now();\n    let expiration_time: Option<DateTime<Utc>> = expiration.clone().map(|exp| {\n        let std_duration: Duration = humantime::parse_duration(&exp).unwrap();\n        Utc::now() + std_duration\n    });\n\n    let bucket_name = env::var(\"INGEST_SERVER__BUCKET\").expect(\"INGEST_SERVER__BUCKET must be set\");\n    let ingest_batch_size = env::var(\"INGEST_BATCH_SIZE\").expect(\"INGEST_BATCH_SIZE must be set\");\n    let ingest_server_url = env::var(\"INGEST_SERVER__URL\").expect(\"INGEST_SERVER__URL must be set\");\n    let task_url = format!(\"{}/task/{}\", ingest_server_url, task_id);\n\n    let file_id = Uuid::new_v4().to_string();\n    let buffer: Vec<u8> = std::fs::read(file.file.path())?;\n\n    if is_valid_pdf(&buffer)? {\n        let file_size = file.size;\n        let page_count = match Document::load_mem(&buffer) {\n            Ok(doc) => doc.get_pages().len() as i32,\n            Err(_) => {\n                return Err(\"Unable to count pages\".into());\n            }\n        };\n\n        let file_name = file.file_name.as_ref().map(String::as_str).unwrap_or(\"unknown.pdf\");\n        let s3_path = format!(\n            \"s3://{}/{}/{}/{}/{}\",\n            bucket_name,\n            user_id,\n            task_id,\n            file_id,\n            file_name\n        );\n        let output_extension = model.get_extension();\n        let output_s3_path = s3_path.replace(\".pdf\", &format!(\".{}\", output_extension));\n\n        if upload_to_s3(&s3_path, file_name, buffer, None).await? {\n            let tx = client.transaction().await?;\n\n            tx.execute(\n                \"INSERT INTO ingestion_tasks (task_id, file_count, total_size, total_pages, created_at, finished_at, api_key, url, status, model, expiration_time) \n                 VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11) \n                 ON CONFLICT (task_id) DO NOTHING\",\n                &[\n                    &task_id,\n                    &1i32,\n                    &(file_size as i64),\n                    &page_count,\n                    &created_at,\n                    &None::<String>,\n                    &api_key,\n                    &format!(\"{}/task/{}\", ingest_server_url, task_id),\n                    &Status::Starting.to_string(),\n                    &model.to_string(),\n                    &expiration_time\n                ]\n            ).await?;\n\n            tx.execute(\n                \"INSERT INTO ingestion_files (file_id, task_id, file_name, file_size, page_count, created_at, status, input_location, output_location, model) \n                 VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10) \n                 ON CONFLICT (file_id) DO NOTHING\",\n                &[\n                    &file_id,\n                    &task_id,\n                    &file.file_name,\n                    &(file_size as i64),\n                    &page_count,\n                    &created_at,\n                    &Status::Starting.to_string(),\n                    &s3_path,\n                    &output_s3_path,\n                    &model.to_string(),\n                ]\n            ).await?;\n\n            tx.commit().await?;\n\n            let extraction_payload = ExtractionPayload {\n                model: model.clone(),\n                input_location: s3_path,\n                output_location: output_s3_path,\n                expiration: None,\n                batch_size: Some(ingest_batch_size.parse::<i32>().unwrap()),\n                file_id,\n                task_id: task_id.clone(),\n            };\n\n            let _ = produce_extraction_payloads(extraction_payload).await?;\n\n            return Ok(TaskResponse {\n                task_id: task_id.clone(),\n                status: Status::Starting,\n                created_at,\n                finished_at: None,\n                expiration_time,\n                file_url: None,\n                task_url: Some(task_url),\n                message: \"Extraction started\".to_string(),\n                model: model.to_external(),\n            });\n        } else {\n            return Err(\"Failed to upload file\".into());\n        }\n    } else {\n        return Err(\"Not a valid PDF\".into());\n    }\n\n}\n"
        }
    ]
}