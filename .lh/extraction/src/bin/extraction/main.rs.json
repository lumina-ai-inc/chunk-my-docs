{
    "sourceFile": "extraction/src/bin/extraction/main.rs",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 1,
            "patches": [
                {
                    "date": 1724531102345,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1724531127325,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,7 +1,7 @@\n use humantime::format_duration;\n-use models::api::{ extraction::{ ExtractionPayload, ModelInternal }, task::Status };\n-use models::rrq::{ produce::ProducePayload, queue::QueuePayload };\n+use crate::models::api::{ extraction::{ ExtractionPayload, ModelInternal }, task::Status };\n+use crate::models::rrq::{ produce::ProducePayload, queue::QueuePayload };\n use serde_json::json;\n use shared::rrq::{ consumer::consumer, service::produce };\n use shared::storage_service::services::{ download_to_tempfile, upload_to_s3 };\n use uuid::Uuid;\n"
                }
            ],
            "date": 1724531102345,
            "name": "Commit-0",
            "content": "use humantime::format_duration;\nuse models::api::{ extraction::{ ExtractionPayload, ModelInternal }, task::Status };\nuse models::rrq::{ produce::ProducePayload, queue::QueuePayload };\nuse serde_json::json;\nuse shared::rrq::{ consumer::consumer, service::produce };\nuse shared::storage_service::services::{ download_to_tempfile, upload_to_s3 };\nuse uuid::Uuid;\nuse std::{ fs, path::PathBuf };\nuse chrono::Utc;\n\nmod extraction_config;\nmod grobid;\nmod pdla;\nmod pdf;\nuse crate::grobid::grobid_extraction;\nuse crate::pdla::pdla_extraction;\nuse extraction_config::Config;\n\npub async fn log_task(\n    task_id: String,\n    file_id: String,\n    status: Status,\n    message: Option<String>,\n    finished_at: Option<String>\n) -> Result<(), Box<dyn std::error::Error>> {\n    let config = Config::from_env()?;\n\n    println!(\"Prepared status: {:?}\", status);\n    println!(\"Prepared task_id: {}\", task_id);\n    println!(\"Prepared file_id: {}\", file_id);\n\n    let task_query = format!(\n        \"UPDATE ingestion_tasks SET status = '{:?}', message = '{}', finished_at = '{:?}' WHERE task_id = '{}'\",\n        status,\n        message.unwrap_or_default(),\n        finished_at.unwrap_or_default(),\n        task_id\n    );\n\n    let files_query = format!(\n        \"UPDATE ingestion_files SET status = '{:?}' WHERE task_id = '{}' AND file_id = '{}'\",\n        status,\n        task_id,\n        file_id\n    );\n\n    let payloads = vec![\n        ProducePayload {\n            queue_name: config.logging_queue.clone(),\n            publish_channel: None,\n            payload: json!(task_query),\n            max_attempts: Some(3),\n            item_id: Uuid::new_v4().to_string(),\n        },\n        ProducePayload {\n            queue_name: config.logging_queue,\n            publish_channel: None,\n            payload: json!(files_query),\n            max_attempts: Some(3),\n            item_id: Uuid::new_v4().to_string(),\n        }\n    ];\n\n    produce(payloads).await?;\n\n    Ok(())\n}\n\nasync fn process(payload: QueuePayload) -> Result<(), Box<dyn std::error::Error>> {\n    let extraction_item: ExtractionPayload = serde_json::from_value(payload.payload)?;\n    let task_id = extraction_item.task_id.clone();\n    let file_id = extraction_item.file_id.clone();\n\n    println!(\"{:?}\", extraction_item.clone());\n\n    log_task(\n        task_id.clone(),\n        file_id.clone(),\n        Status::Processing,\n        Some(format!(\"Task processing | Retry ({}/{})\", payload.attempt, payload.max_attempts)),\n        None\n    ).await?;\n\n    let result: Result<(), Box<dyn std::error::Error>> = (async {\n        let temp_file = download_to_tempfile(&extraction_item.input_location).await?;\n        println!(\"Downloaded file to {:?}\", temp_file.path());\n\n        let output_path: PathBuf;\n\n        if extraction_item.model == ModelInternal::Grobid {\n            output_path = grobid_extraction(temp_file.path()).await?;\n        } else if\n            extraction_item.model == ModelInternal::Pdla ||\n            extraction_item.model == ModelInternal::PdlaFast\n        {\n            output_path = pdla_extraction(\n                temp_file.path(),\n                extraction_item.model,\n                extraction_item.batch_size\n            ).await?;\n        } else {\n            return Err(\"Invalid model\".into());\n        }\n\n        upload_to_s3(\n            &extraction_item.output_location,\n            output_path.clone().to_str().unwrap(),\n            fs::read(output_path)?,\n            extraction_item.expiration.map(|d| format_duration(d).to_string()).as_deref()\n        ).await?;\n\n        if temp_file.path().exists() {\n            if let Err(e) = std::fs::remove_file(temp_file.path()) {\n                eprintln!(\"Error deleting temporary file: {:?}\", e);\n            }\n        }\n\n        Ok(())\n    }).await;\n\n    match result {\n        Ok(_) => {\n            log_task(\n                task_id.clone(),\n                file_id.clone(),\n                Status::Succeeded,\n                Some(\"Task succeeded\".to_string()),\n                Some(Utc::now().to_string())\n            ).await?;\n            println!(\"Task succeeded\");\n            Ok(())\n        }\n        Err(e) => {\n            eprintln!(\"Error processing task: {:?}\", e);\n            if payload.attempt >= payload.max_attempts {\n                log_task(\n                    task_id.clone(),\n                    file_id.clone(),\n                    Status::Failed,\n                    Some(e.to_string()),\n                    Some(Utc::now().to_string())\n                ).await?;\n                println!(\"Task failed\");\n            }\n            Err(e)\n        }\n    }\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Box<dyn std::error::Error>> {\n    let config = Config::from_env()?;\n    consumer(process, config.queue, 1, 600).await?;\n    Ok(())\n}\n"
        }
    ]
}